{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PRÁCTICA 1 - TIPOLOGÍA Y CICLO DE VIDA DE LOS DATOS\n",
    "\n",
    "Caso práctico orientado a aprender a identificar los datos relevantes para un proyecto analítico y usar herramientas de extracción de datos. \n",
    "\n",
    "El objetivo de esta actividad será la creación de un dataset a partir de los datos contenidos en un sitio web. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función descargaPaginaWeb que permite recuperar la información correspondiente a la respuesta de la petición. \n",
    "# url: corresponde con la url del sitio donde se hará el web scraping\n",
    "def descargaPaginaWeb(url):\n",
    "    respuesta = requests.get(\n",
    "        url,\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:93.0) Gecko/20100101 Firefox/93.0'\n",
    "        }\n",
    "    )\n",
    "    return respuesta\n",
    "\n",
    "# Funcion extraerCaracteristica que actualiza el valor de la caracteristica según el valor de posicion. La función retorna\n",
    "# un diccionario (sismo) al que se le ha añadido la característica\n",
    "# caracteristica: característica\n",
    "# posicion: indica qué etiqueta tiene la característica\n",
    "# sismo: almacena todas las caracteristicas de un sismo en un diccionario\n",
    "def extraerCaracteristica(caracteristica, posicion, sismo):\n",
    "    if posicion == 0:\n",
    "        sismo['Evento'] = caracteristica\n",
    "    elif posicion == 1:\n",
    "        sismo['Fecha'] = caracteristica\n",
    "    elif posicion == 2:\n",
    "        sismo['HoraUTC'] = caracteristica\n",
    "    elif posicion == 3:\n",
    "        sismo['HoraLocal'] = caracteristica\n",
    "    elif posicion == 4:\n",
    "        sismo['Latitud'] = caracteristica\n",
    "    elif posicion == 5:\n",
    "        sismo['Longitud'] = caracteristica\n",
    "    elif posicion == 6:\n",
    "        sismo['Profundidad'] = caracteristica\n",
    "    elif posicion == 7:\n",
    "        sismo['Magnitud'] = caracteristica\n",
    "    elif posicion == 8:\n",
    "        sismo['Tipo_Magnitud'] = caracteristica\n",
    "    elif posicion == 9:\n",
    "        sismo['Intensidad'] = caracteristica\n",
    "    elif posicion == 10:\n",
    "        sismo['Localizacion'] = caracteristica\n",
    "    elif posicion == 11:\n",
    "        sismo['Imagen'] = caracteristica\n",
    "    return sismo\n",
    "\n",
    "# Función extraerImagen que extrae la url de una imagen contenida en otra url de información sobre un sismo sobre la que\n",
    "# hay que hacer web scraping. La función retorna la url de la imagen o NA si no hay información de la imagen.\n",
    "# tag: etiqueta html\n",
    "# parametro: parametro que se añade a la etiqueta\n",
    "def extraerImagen(tag, parametro):\n",
    "    info_form = tag.find('form')\n",
    "    output = info_form['action'] + '?evid=' + parametro\n",
    "    pagina = descargaPaginaWeb(output)\n",
    "    contenido_web = BeautifulSoup(pagina.text, 'html.parser')\n",
    "    imagen = contenido_web.find('img', attrs={\"alt\": \"Foto Detalle\"})\n",
    "    if type(imagen['src']) != 'str':\n",
    "        return 'NA'\n",
    "    else:\n",
    "        return imagen['src']\n",
    "    \n",
    "        \n",
    "# Función extraerDatos que extrae de una página web la información requerida. La función retorna una lista con la \n",
    "# información de todos los sismos producidos (cada sismo se almacena en un diccionario con los nombres de los campos y \n",
    "# sus valores).\n",
    "# respuesta: respuesta obtenida al preguntar a una url específica\n",
    "def extraerDatos(respuesta):\n",
    "    sismos = []\n",
    "    contenido_web = BeautifulSoup(respuesta.text, 'html.parser')\n",
    "    tabla_sismos_30 = contenido_web.table\n",
    "    filas = tabla_sismos_30.findAll('td')\n",
    "    elemento = 0\n",
    "    sismo = {}\n",
    "    for fila in filas:\n",
    "        if elemento < 11:\n",
    "            sismo = extraerCaracteristica(fila.text.strip(), elemento, sismo)\n",
    "            elemento = elemento + 1\n",
    "        else:\n",
    "            # Si se quiere guardar el archivo gif con la imagen del lugar del sismo\n",
    "            #sismo = extraerCaracteristica(extraerImagen(fila, sismo['Evento']), elemento, sismo)\n",
    "            sismo = extraerCaracteristica('NA', elemento, sismo)\n",
    "            elemento = 0\n",
    "            sismos.append(sismo)\n",
    "            sismo = {}\n",
    "    return sismos\n",
    "\n",
    "# Función crearArchivoCSVDesdeLista que crea un archivo csv a partir de una lista de diccionarios.\n",
    "# lista: lista con los diccionarios\n",
    "# nombreArchivo: nombre del archivo csv\n",
    "def crearArchivoCSVDesdeLista(lista, nombreArchivo):\n",
    "    campos = ['Evento', 'Fecha', 'HoraUTC', 'HoraLocal', 'Latitud', 'Longitud', 'Profundidad', 'Magnitud', \n",
    "              'Tipo_Magnitud', 'Intensidad', 'Localizacion', 'Imagen']\n",
    "    try:\n",
    "        with open(nombreArchivo + '.csv', 'w', newline='') as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=campos)\n",
    "            writer.writeheader()\n",
    "            for elemento in lista:\n",
    "                writer.writerow(elemento)\n",
    "    except IOError:\n",
    "        print(\"I/O error\")\n",
    "\n",
    "\n",
    "# Función principal\n",
    "def main():\n",
    "    respuesta = descargaPaginaWeb('https://www.ign.es/web/ign/portal/ultimos-terremotos/-/ultimos-terremotos/get30dias')\n",
    "    lista = extraerDatos(respuesta)\n",
    "    crearArchivoCSVDesdeLista(lista, 'dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
