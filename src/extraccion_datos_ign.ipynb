{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PRÁCTICA 1 - TIPOLOGÍA Y CICLO DE VIDA DE LOS DATOS\n",
    "\n",
    "Caso práctico orientado a aprender a identificar los datos relevantes para un proyecto analítico y usar herramientas de extracción de datos. \n",
    "\n",
    "El objetivo de esta actividad será la creación de un dataset a partir de los datos contenidos en un sitio web. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import csv\n",
    "import pandas\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función descargaPaginaWeb que permite recuperar la información correspondiente a la respuesta de la petición. \n",
    "# url: corresponde con la url del sitio donde se hará el web scraping\n",
    "def descargaPaginaWeb(url):\n",
    "    respuesta = requests.get(\n",
    "        url,\n",
    "        #headers = {\n",
    "        #    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:93.0) Gecko/20100101 Firefox/93.0'\n",
    "        #}\n",
    "    )\n",
    "    return respuesta\n",
    "\n",
    "# Función extraerImagen que extrae la url de una imagen contenida en otra url de información sobre un sismo sobre la que\n",
    "# hay que hacer web scraping. La función retorna la url de la imagen o NA si no hay información de la imagen.\n",
    "# tag: etiqueta html\n",
    "# parametro: parametro que se añade a la etiqueta\n",
    "def extraerImagen(tag, parametro):\n",
    "    info_form = tag.find('form')\n",
    "    output = info_form['action'] + '?evid=' + parametro\n",
    "    pagina = descargaPaginaWeb(output)\n",
    "    contenido_web = BeautifulSoup(pagina.text, 'html.parser')\n",
    "    imagen = contenido_web.find('img', attrs={\"alt\": \"Foto Detalle\"})\n",
    "    if type(imagen['src']) != 'str':\n",
    "        return 'NA'\n",
    "    else:\n",
    "        return imagen['src']\n",
    "    \n",
    "        \n",
    "# Función extraerDatos que extrae de una página web la información requerida. La función retorna una lista con la \n",
    "# información de todos los sismos producidos (cada sismo se almacena en un diccionario con los nombres de los campos y \n",
    "# sus valores).\n",
    "# respuesta: respuesta obtenida al preguntar a una url específica\n",
    "def extraerDatos(respuesta):\n",
    "    contenido_web  = BeautifulSoup(respuesta.text, 'html.parser')\n",
    "    sismos = []\n",
    "    nombre_columnas = []\n",
    "    tabla = contenido_web .find_all('table')[0]\n",
    "    filas = tabla.find_all('tr')\n",
    "    for fila in filas:\n",
    "        cols = fila.find_all('td')\n",
    "        cols = [ele.text.strip() for ele in cols]\n",
    "        nom_cols = fila.find_all('th')\n",
    "        nom_cols = [ele.text.strip() for ele in nom_cols]\n",
    "        if len(nom_cols) > 0:\n",
    "            nombre_columnas = nom_cols\n",
    "        if len(cols) > 0:\n",
    "            sismos.append(cols) \n",
    "\n",
    "    sismos_df = pandas.DataFrame(sismos,columns=nombre_columnas)\n",
    "    return sismos_df\n",
    "    \n",
    "# Función convertirDatos que convierte los datos de str al tipo correspondiente.\n",
    "# dataframe\n",
    "# nombreArchivo: nombre del archivo csv\n",
    "def convertirDatos(dataFrame):\n",
    "    dataFrame['Fecha'] = pandas.to_datetime(data_frame['Fecha'], format='%d/%m/%Y')\n",
    "    dataFrame['Hora UTC'] = pandas.to_datetime(data_frame['Hora UTC'], format='%H:%M:%S')\n",
    "    dataFrame['Hora Local(*)'] = pandas.to_datetime(data_frame['Hora Local(*)'], format='%H:%M:%S')\n",
    "    dataFrame['Profundidad(km)'] = pandas.to_numeric(data_frame['Profundidad(km)'])\n",
    "    dataFrame['Magnitud'] = pandas.to_numeric(data_frame['Magnitud'])\n",
    "    dataFrame['Latitud'] = pandas.to_numeric(data_frame['Latitud'])\n",
    "    dataFrame['Longitud'] = pandas.to_numeric(data_frame['Longitud'])\n",
    "    \n",
    "# Función crearArchivoCSVDesdeLista que crea un archivo csv a partir de una lista de diccionarios.\n",
    "# lista: lista con los diccionarios\n",
    "# nombreArchivo: nombre del archivo csv\n",
    "def crearArchivoCSVDesdeLista(dataFrame, nombreArchivo):\n",
    "    dataFrame.to_csv(nombreArchivo,index=False)\n",
    "\n",
    "\n",
    "# Función principal\n",
    "def main():\n",
    "    respuesta = descargaPaginaWeb('https://www.ign.es/web/ign/portal/ultimos-terremotos/-/ultimos-terremotos/get30dias')\n",
    "    lista = extraerDatos(respuesta)\n",
    "    crearArchivoCSVDesdeLista(lista, 'dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
